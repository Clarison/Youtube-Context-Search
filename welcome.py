import streamlit as st
from urllib.parse import urlparse, parse_qs
import openai
import pinecone

index_name = 'openai-youtube-transcriptions'

# initialize connection to pinecone (get API key at app.pinecone.io)
pinecone.init(
    api_key="deb8442d-d32a-4485-a5b7-35f577f68c01",
    environment="us-west4-gcp"  # may be different, check at app.pinecone.io
)

# connect to index
index = pinecone.Index(index_name)
# view index stats
index.describe_index_stats()



openai.api_key = st.secrets["openai_api_key"]
st.title("YouTube Transcript Embeddings Search")


default_text = 'what is the size'

query = st.text_input("Enter your Question", value=default_text)


def complete(prompt):
    # query text-davinci-003
    res = openai.Completion.create(
        engine='text-davinci-003',
        prompt=prompt,
        temperature=0,
        max_tokens=400,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )
    return res['choices'][0]['text'].strip()

limit = 3750

embed_model = "text-embedding-ada-002"

def retrieve(query):
    res = openai.Embedding.create(
        input=[query],
        engine=embed_model
    )

    # retrieve from Pinecone
    xq = res['data'][0]['embedding']

    # get relevant contexts
    res = index.query(xq, top_k=3, include_metadata=True)
    contexts = [
        x['metadata']['text'] for x in res['matches']
    ]

    # build our prompt with the retrieved contexts included
    prompt_start = (
        "Answer the question based on the context below.\n\n"+
        "Context:\n"
    )
    prompt_end = (
        f"\n\nQuestion: {query}\nAnswer:"
    )
    # append contexts until hitting limit
    for i in range(1, len(contexts)):
        if len("\n\n---\n\n".join(contexts[:i])) >= limit:
            prompt = (
                prompt_start +
                "\n\n---\n\n".join(contexts[:i-1]) +
                prompt_end
            )
            break
        elif i == len(contexts)-1:
            prompt = (
                prompt_start +
                "\n\n---\n\n".join(contexts) +
                prompt_end
            )
    return prompt

st.header("Generated by AI")
st.write(complete(query))

query_with_contexts = retrieve(query)



st.header("Generated By AI + Pinecode")
st.write(complete(query_with_contexts))
